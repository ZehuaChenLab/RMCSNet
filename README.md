# RMCSNet

Road extraction from remote sensing imagery is crucial for applications in autonomous driving, smart transportation, and disaster response. However, this task faces challenges such as complex backgrounds, shadow interference, and texture confusion, which degrade both optical and physical information of road regions, thereby hindering road detection and classification. To address these issues, we propose a road extraction method that integrates contextual information with Swin Transformer, called RMCSNet. The Parallel Attention Module (PAM) leverages multi-scale feature maps for parallel processing, enhancing the model's focus on both local and global road features. The Context-Aware Multi-Scale Fusion Module (CAMF) incorporates Swin Transformer to improve the model's ability to capture global and contextual information. The Multi-Scale Decoder (MSD) adopts an innovative reparameterized focusing convolution technique to optimize the feature map reconstruction process. Extensive experiments on the DeepGlobe and Massachusetts public datasets yielded F1 of 82.81% and 81.69%, and IoUs of 71.66% and 68.12%, respectively. The results confirm that our method demonstrates superior connectivity in road label extraction. The code will be made available upon acceptance of the paper.
